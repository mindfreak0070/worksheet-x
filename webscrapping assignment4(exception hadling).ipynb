{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Read all the problem statements, notes carefully and scrape the required data using any web scraping tool of \n",
    "your choice.\n",
    " You have to handle commonly occurring EXCEPTIONS by using exception handling programing. To get \n",
    "information about selenium Exceptions. You may visit following links:\n",
    "1. https://selenium-python.readthedocs.io/api.html\n",
    "2. https://www.guru99.com/exception-handling-selenium.html\n",
    "3. https://stackoverflow.com/questions/38022658/selenium-python-handling-no-such-element￾exception/38023345"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty dictionary\n",
    "most_Viewed_youtube = {}\n",
    "most_Viewed_youtube['Rank'] = []\n",
    "most_Viewed_youtube['Name'] = []\n",
    "most_Viewed_youtube['Artist'] = []\n",
    "most_Viewed_youtube['Upload_date'] = []\n",
    "most_Viewed_youtube['Views'] = []\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the all data\n",
    "for i in range(0,30):\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        #rank\n",
    "        rank = driver.find_element_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']\")\n",
    "        most_Viewed_youtube['Rank'].append(rank.text)\n",
    "        time.sleep(2)\n",
    "            \n",
    "        #name\n",
    "        name = driver.find_element_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']\")\n",
    "        most_Viewed_youtube['Name'].append(name.text)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #artist\n",
    "        artist = driver.find_element_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']\")\n",
    "        most_Viewed_youtube['Artist'].append(artist.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "        #upload_date\n",
    "        uploadDate = driver.find_element_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']\")\n",
    "        most_Viewed_youtube['Upload_date'].append(uploadDate.text)\n",
    "        time.sleep(2)\n",
    "    \n",
    "        #views\n",
    "        view = driver.find_element_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']\")\n",
    "        most_Viewed_youtube['Views'].append(view.text)\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException as n:\n",
    "        print(\"Exception\",n)\n",
    "        \n",
    "most_Viewed_youtube"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unable to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \" https://www.bcci.tv/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\")\n",
    "fixture.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title=driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__format\"]') \n",
    "Match_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Title=[]\n",
    "for i in Match_title:\n",
    "    Match_Title.append(i.text)\n",
    "    \n",
    "Match_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_series=driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]') \n",
    "Match_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Series=[]\n",
    "for i in Match_series:\n",
    "    Match_Series.append(i.text)\n",
    "    \n",
    "Match_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_place=driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]') \n",
    "Match_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Info=[]\n",
    "for i in Match_place:\n",
    "    Match_Info.append(i.text.replace('\\n','-'))\n",
    "    \n",
    "Match_Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_time=driver.find_elements_by_xpath('//span[@class=\"fixture__time\"]') \n",
    "Match_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Time=[]\n",
    "for i in Match_time:\n",
    "    Match_Time.append(i.text)\n",
    "    \n",
    "Match_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_date=driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]')\n",
    "Match_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Date=[]\n",
    "for i in Match_date:\n",
    "    Match_Date.append(i.text.replace('\\n',','))\n",
    "    \n",
    "Match_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_desc=pd.DataFrame({})\n",
    "Match_desc['info']=Match_Info\n",
    "Match_desc['time']=Match_Time\n",
    "Match_desc['date']=Match_Date\n",
    "Match_desc['series']=Match_Series\n",
    "Match_desc['title']=Match_Title\n",
    "Match_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exception handling method\n",
    "\n",
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \" https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "\n",
    "button=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\")\n",
    "button.click()\n",
    "\n",
    "fixture=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\")\n",
    "fixture.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(value):\n",
    "    \n",
    "    stri = '' #empty string intillation\n",
    "    #return value\n",
    "    for i in value:\n",
    "        stri += i \n",
    "        \n",
    "    return stri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "international_fixture = {}\n",
    "international_fixture['Match_title'] = []\n",
    "international_fixture['Series'] = []\n",
    "international_fixture['Place'] = []\n",
    "international_fixture['Date'] = []\n",
    "international_fixture['Time'] = []\n",
    "\n",
    "time.sleep(3)\n",
    "#Match title\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "    international_fixture['Match_title'].append(i.text)\n",
    "\n",
    "# Series\n",
    "for i in driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\"):\n",
    "    international_fixture['Series'].append(i.text)\n",
    "\n",
    "#place\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\"):\n",
    "    international_fixture['Place'].append(i.text)\n",
    "\n",
    "# Date and Time\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']\"):\n",
    "    \n",
    "    time = i.get_attribute(\"innerText\").split(\" \")[4:]\n",
    "    times= list_to_string(time)\n",
    "    international_fixture['Time'].append(times)\n",
    "    \n",
    "    #date\n",
    "    date = i.get_attribute(\"innerText\").split(\" \")[:3]\n",
    "    dates= list_to_string(date)\n",
    "    international_fixture['Date'].append(dates)\n",
    "\n",
    "International_fixture = pd.DataFrame(international_fixture)\n",
    "International_fixture"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dont know where to use exception handling method: with help  able to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \"https://www.guru99.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selenium=driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[1]/div/ul[1]/li[3]/a\")\n",
    "selenium.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sele_exception=driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div/main/div/article/div/div/table[5]/tbody/tr[34]/td[1]/a\")\n",
    "sele_exception.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selenium_exception = {}\n",
    "selenium_exception['Name'] = []\n",
    "selenium_exception['Description'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 2\n",
    "\n",
    "for i in range(0,41):\n",
    "    \n",
    "    name = driver.find_element_by_xpath(f\"//table[@class='table table-striped']/tbody/tr[{counter}]/td[1]\").text\n",
    "    selenium_exception['Name'].append(name)\n",
    "    desc = driver.find_element_by_xpath(f\"//table[@class='table table-striped']/tbody/tr[{counter}]/td[2]\").text\n",
    "    selenium_exception['Description'].append(desc)\n",
    "    \n",
    "    counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selenium_exception = pd.DataFrame(selenium_exception)\n",
    "Selenium_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "econmy=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "econmy.click()\n",
    "\n",
    "india=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "india.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "state.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_state = {}\n",
    "gdp_state['Rank'] = []\n",
    "gdp_state['State'] = []\n",
    "gdp_state['GSDP at current price (19-20)'] = []\n",
    "gdp_state['GSDP at current price (18-19)'] = []\n",
    "gdp_state['Share(18-19)'] =[]\n",
    "gdp_state['GDP($ billion)'] = []\n",
    "\n",
    "\n",
    "counter = 1\n",
    "time.sleep(2)\n",
    "for i in range(len(driver.find_elements_by_xpath(\"//table[@id='table_id']/tbody/tr\"))):\n",
    "    \n",
    "    #rank\n",
    "    rank = driver.find_element_by_xpath(f\"//table[@id='table_id']/tbody/tr[{counter}]/td[1]\")\n",
    "    gdp_state['Rank'].append(rank.text)\n",
    "    \n",
    "    state = driver.find_element_by_xpath(f\"//table[@id='table_id']/tbody/tr[{counter}]/td[2]\")\n",
    "    gdp_state['State'].append(state.text)   \n",
    "               \n",
    "    #gsdb19_20\n",
    "    gsdb19_20= driver.find_element_by_xpath(f\"//table[@id='table_id']/tbody/tr[{counter}]/td[3]\")\n",
    "    gdp_state['GSDP at current price (19-20)'].append(gsdb19_20.text)\n",
    "               \n",
    "    \n",
    "    gsdb18_19= driver.find_element_by_xpath(f\"//table[@id='table_id']/tbody/tr[{counter}]/td[4]\")\n",
    "    gdp_state['GSDP at current price (18-19)'].append(gsdb18_19.text)   \n",
    "    \n",
    "    share= driver.find_element_by_xpath(f\"//table[@id='table_id']/tbody/tr[{counter}]/td[5]\")\n",
    "    gdp_state['Share(18-19)'].append(share.text)\n",
    "               \n",
    "    \n",
    "    gdb = driver.find_element_by_xpath(f\"//table[@id='table_id']/tbody/tr[{counter}]/td[6]\")\n",
    "    gdp_state['GDP($ billion)'].append(gdb.text)   \n",
    "    \n",
    "    counter +=1  # moving to next row\n",
    "    time.sleep(2)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_state = pd.DataFrame(gdp_state)\n",
    "gdp_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element_by_xpath(\"//ul[@class='d-lg-flex list-style-none']/li[4]\")\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = {}\n",
    "trending['Repository_Title'] = []\n",
    "trending['Repository_Description'] = []\n",
    "trending['Contributors_Count'] = []\n",
    "trending['Language_Used'] = []\n",
    "\n",
    "titles = driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in titles:\n",
    "    trending['Repository_Title'].append(i.text)\n",
    "time.sleep(2)\n",
    "\n",
    "count = 1\n",
    "for i in range(len(driver.find_elements_by_xpath(\"//article[@class='Box-row']\"))):\n",
    "    \n",
    "    try:\n",
    "        descriptions = driver.find_element_by_xpath(f\"//article[@class='Box-row'][{count}]/p[1]\")\n",
    "        trending['Repository_Description'].append(descriptions.text) \n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        trending['Repository_Description'].append(\"-\")\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "contributor_counts = driver.find_elements_by_xpath(\"//div[@class='f6 color-text-secondary mt-2']/a[2]\")\n",
    "for i in contributor_counts:\n",
    "    trending['Contributors_Count'].append(i.text)\n",
    "time.sleep(2)\n",
    "\n",
    "lan_count = 1\n",
    "for i in range(len(driver.find_elements_by_xpath(\"//div[@class='f6 color-text-secondary mt-2']\"))):\n",
    "    try:\n",
    "        langu = driver.find_element_by_xpath(f\"//article[@class='Box-row'][{lan_count}]/div[2]/span/span[2]\")\n",
    "        trending['Language_Used'].append(langu.text) \n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        trending['Language_Used'].append(\"-\")\n",
    "    lan_count += 1\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trending_repositories = pd.DataFrame(trending)\n",
    "Trending_repositories"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "   A) Song name\n",
    "   B) Artist name\n",
    "   C) Last week rank\n",
    "   D) Peak rank\n",
    "   E) Weeks on board\n",
    "   \n",
    "  Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart= driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]/a\")\n",
    "chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_100 = driver.find_element_by_xpath(\"/html/body/main/div[2]/div/div[1]/a/div[2]/div[1]\")\n",
    "hot_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = {}\n",
    "top100[\"SongName\"] = []\n",
    "top100[\"ArtistName\"] = []\n",
    "top100[\"Last_week_rank\"] = []\n",
    "top100[\"Peak_rank\"] = []\n",
    "top100[\"Weeks_on_board\"] = []\n",
    "\n",
    "songName = driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[1]\")\n",
    "for i in songName:\n",
    "    top100[\"SongName\"].append(i.text)\n",
    "\n",
    "artistName = driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[2]\")\n",
    "for i in artistName:\n",
    "    top100[\"ArtistName\"].append(i.text)\n",
    "    \n",
    "lastWeek = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lastWeek:\n",
    "    top100[\"Last_week_rank\"].append(i.text)\n",
    "    \n",
    "peakRank = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peakRank:\n",
    "    top100[\"Peak_rank\"].append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wob = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in wob:\n",
    "    top100[\"Weeks_on_board\"].append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top100So = pd.DataFrame(top100)\n",
    "Top100So"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req=driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/ul[1]/li[2]/a/div\")\n",
    "req.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_xpath(\"//form[@class='qsbFormJS']\")\n",
    "search_bar\n",
    "\n",
    "search_bar.send_keys(\"data science\")\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# not able to identify problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "\n",
    "**You have to find the following details:**\n",
    "\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Novels = {}\n",
    "Novels[\"Book_Name\"] = []\n",
    "Novels[\"Author_Name\"] = []\n",
    "Novels[\"Volume_Sold\"] = []\n",
    "Novels[\"Publisher\"] = []\n",
    "Novels[\"Genre\"] = []\n",
    "\n",
    "#Scraping the detail\n",
    "\n",
    "count = 1\n",
    "for i in range(len(driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr\"))):\n",
    "    \n",
    "    book_name = driver.find_element_by_xpath(f\"//table[@class='in-article sortable']/tbody/tr[{count}]/td[2]\")\n",
    "    Novels[\"Book_Name\"].append(book_name.text)\n",
    "    \n",
    "    author_name = driver.find_element_by_xpath(f\"//table[@class='in-article sortable']/tbody/tr[{count}]/td[3]\")\n",
    "    Novels[\"Author_Name\"].append(author_name.text)\n",
    "    \n",
    "    volume_name = driver.find_element_by_xpath(f\"//table[@class='in-article sortable']/tbody/tr[{count}]/td[4]\")\n",
    "    Novels[\"Volume_Sold\"].append(volume_name.text)\n",
    "    \n",
    "    publisher = driver.find_element_by_xpath(f\"//table[@class='in-article sortable']/tbody/tr[{count}]/td[5]\")\n",
    "    Novels[\"Publisher\"].append(publisher.text)\n",
    "    \n",
    "    genre = driver.find_element_by_xpath(f\"//table[@class='in-article sortable']/tbody/tr[{count}]/td[6]\")\n",
    "    Novels[\"Genre\"].append(genre.text)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "Novels_selling = pd.DataFrame(Novels)\n",
    "Novels_selling"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "series = {}\n",
    "series['Name'] = []\n",
    "series['YearSpan'] = []\n",
    "series['Genre'] = []\n",
    "series['RunTime'] = []\n",
    "series['Rating'] = []\n",
    "series['Votes'] = []\n",
    "\n",
    "names = driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "for i in names:\n",
    "    series['Name'].append(i.text)\n",
    "        \n",
    "yearSpan = driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "for i in yearSpan:\n",
    "    series['YearSpan'].append(i.text.replace('(','').replace(')',''))\n",
    "\n",
    "        \n",
    "genre = driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in genre:\n",
    "    series['Genre'].append(i.text)\n",
    "        \n",
    "runtime = driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in runtime:\n",
    "    series['RunTime'].append(i.text)\n",
    "        \n",
    "        \n",
    "rating = driver.find_elements_by_xpath(\"//div[@class ='ipl-rating-star small']/span[2]\")\n",
    "for i in rating:\n",
    "    series['Rating'].append(i.text)\n",
    "\n",
    "votes = driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "for i in votes:\n",
    "    series['Votes'].append(i.text)        \n",
    "\n",
    "    \n",
    "IMDB_Series = pd.DataFrame(series)\n",
    "IMDB_Series\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Data</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial Characters</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>6000</td>\n",
       "      <td>7</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Audiology (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>-</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Audiology (Standardized)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226</td>\n",
       "      <td>69</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Real</td>\n",
       "      <td>398</td>\n",
       "      <td>8</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>205</td>\n",
       "      <td>26</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Badges</td>\n",
       "      <td>Univariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balance Scale</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>625</td>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Balloons</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>286</td>\n",
       "      <td>9</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>699</td>\n",
       "      <td>10</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Breast Cancer Wisconsin (Prognostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>198</td>\n",
       "      <td>34</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>32</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pittsburgh Bridges</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>108</td>\n",
       "      <td>13</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Dataset               Data  \\\n",
       "0                                Abalone      Multivariate    \n",
       "1                                  Adult      Multivariate    \n",
       "2                              Annealing      Multivariate    \n",
       "3           Anonymous Microsoft Web Data                  -   \n",
       "4                             Arrhythmia      Multivariate    \n",
       "5                  Artificial Characters      Multivariate    \n",
       "6                   Audiology (Original)      Multivariate    \n",
       "7               Audiology (Standardized)      Multivariate    \n",
       "8                               Auto MPG      Multivariate    \n",
       "9                             Automobile      Multivariate    \n",
       "10                                Badges  Univariate, Text    \n",
       "11                         Balance Scale      Multivariate    \n",
       "12                              Balloons      Multivariate    \n",
       "13                         Breast Cancer      Multivariate    \n",
       "14    Breast Cancer Wisconsin (Original)      Multivariate    \n",
       "15  Breast Cancer Wisconsin (Prognostic)      Multivariate    \n",
       "16  Breast Cancer Wisconsin (Diagnostic)      Multivariate    \n",
       "17                    Pittsburgh Bridges      Multivariate    \n",
       "18                        Car Evaluation      Multivariate    \n",
       "19                         Census Income      Multivariate    \n",
       "\n",
       "                           Task                    Attribute No_of_instances  \\\n",
       "0               Classification   Categorical, Integer, Real            4177    \n",
       "1               Classification         Categorical, Integer           48842    \n",
       "2               Classification   Categorical, Integer, Real             798    \n",
       "3          Recommender-Systems                  Categorical           37711    \n",
       "4               Classification   Categorical, Integer, Real             452    \n",
       "5               Classification   Categorical, Integer, Real            6000    \n",
       "6               Classification                  Categorical             226    \n",
       "7               Classification                  Categorical             226    \n",
       "8                   Regression            Categorical, Real             398    \n",
       "9                   Regression   Categorical, Integer, Real             205    \n",
       "10              Classification                             -            294    \n",
       "11              Classification                  Categorical             625    \n",
       "12              Classification                  Categorical              16    \n",
       "13              Classification                  Categorical             286    \n",
       "14              Classification                      Integer             699    \n",
       "15  Classification, Regression                         Real             198    \n",
       "16              Classification                         Real             569    \n",
       "17              Classification         Categorical, Integer             108    \n",
       "18              Classification                  Categorical            1728    \n",
       "19              Classification         Categorical, Integer           48842    \n",
       "\n",
       "   No_of_attribute   Year  \n",
       "0               8   1995   \n",
       "1              14   1996   \n",
       "2              38       -  \n",
       "3             294   1998   \n",
       "4             279   1998   \n",
       "5               7   1992   \n",
       "6                -  1987   \n",
       "7              69   1992   \n",
       "8               8   1993   \n",
       "9              26   1987   \n",
       "10              1   1994   \n",
       "11              4   1994   \n",
       "12              4       -  \n",
       "13              9   1988   \n",
       "14             10   1992   \n",
       "15             34   1995   \n",
       "16             32   1995   \n",
       "17             13   1990   \n",
       "18              6   1997   \n",
       "19             14   1996   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Edge('msedgedriver.exe')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "all_dataset=driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "all_dataset.click()\n",
    "\n",
    "repositories = ({})\n",
    "repositories['Dataset']= []\n",
    "repositories['Data'] = []\n",
    "repositories['Task'] = []\n",
    "repositories['Attribute'] = []\n",
    "repositories['No_of_instances'] = []\n",
    "repositories['No_of_attribute'] = []\n",
    "repositories['Year'] = []\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "name = driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\")\n",
    "for i in name:\n",
    "    if len(repositories['Dataset']) < 586:\n",
    "        repositories['Dataset'].append(i.text)\n",
    "    else:\n",
    "        pass\n",
    "     \n",
    "time.sleep(1)\n",
    "for i in range(2,588):\n",
    "    dtype = driver.find_element_by_xpath(f\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{i}]/td[2]/p\")\n",
    "    if dtype.text == \" \":\n",
    "        repositories['Data'].append(\"-\")\n",
    "    else:\n",
    "        repositories['Data'].append(dtype.text)\n",
    "    \n",
    "    task = driver.find_element_by_xpath(f\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{i}]/td[3]/p\")\n",
    "    if task.text == \" \":\n",
    "        repositories['Task'].append(\"-\")\n",
    "    else:\n",
    "        repositories['Task'].append(task.text) \n",
    "        \n",
    "    type = driver.find_element_by_xpath(f\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{i}]/td[4]/p\")\n",
    "    if type.text == \" \":\n",
    "        repositories['Attribute'].append(\"-\")\n",
    "    else:\n",
    "        repositories['Attribute'].append(type.text)\n",
    "        \n",
    "    instance = driver.find_element_by_xpath(f\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{i}]/td[5]/p\")\n",
    "    if instance.text == \" \":\n",
    "        repositories['No_of_instances'].append(\"-\")\n",
    "    else:\n",
    "        repositories['No_of_instances'].append(instance.text) \n",
    "        \n",
    "    num_attribute = driver.find_element_by_xpath(f\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{i}]/td[6]/p\")\n",
    "    if num_attribute.text == \" \":\n",
    "        repositories['No_of_attribute'].append(\"-\")\n",
    "    else:\n",
    "        repositories['No_of_attribute'].append(num_attribute.text)        \n",
    "        \n",
    "    year = driver.find_element_by_xpath(f\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{i}]/td[7]/p\")\n",
    "    if year.text == \" \":\n",
    "        repositories['Year'].append(\"-\")\n",
    "    else:\n",
    "        repositories['Year'].append(year.text)\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#Creating Dataframe\n",
    "UCI_Repositories = pd.DataFrame(repositories)\n",
    "UCI_Repositories.head(20)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "not finding the all data set page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
